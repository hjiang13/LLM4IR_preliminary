#!/usr/bin/env python3
"""
åˆ›å»ºå®Œæ•´çš„è¾“å…¥-è¾“å‡º-IRæ•°æ®é›†
åŒ…å«å®é™…çš„æ•°å€¼æ•°æ®å’Œæ›´è¯¦ç»†çš„å…ƒæ•°æ®
"""

import os
import json
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Any

class CompleteIODatasetCreator:
    """å®Œæ•´çš„è¾“å…¥è¾“å‡ºæ•°æ®é›†åˆ›å»ºå™¨"""
    
    def __init__(self):
        self.base_dir = Path(".")
        self.output_dir = self.base_dir / "io_dataset"
        self.output_dir.mkdir(exist_ok=True)
        
        self.dataset = {
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "version": "1.0",
                "description": "LLM4IRè¾“å…¥-è¾“å‡º-IRæ•°æ®é›†",
                "total_operations": 0,
                "single_operations": 0,
                "pair_operations": 0,
                "data_points": 0
            },
            "operations": {},
            "statistics": {},
            "data_samples": {}
        }
    
    def generate_realistic_data(self, shape: List[int], operation: str) -> np.ndarray:
        """ç”Ÿæˆæ›´çœŸå®çš„æµ‹è¯•æ•°æ®"""
        if operation in ["add", "sub", "mul", "div"]:
            # ç®—æœ¯è¿ç®—ï¼šä½¿ç”¨æœ‰æ„ä¹‰çš„æ•°å€¼èŒƒå›´
            data = np.random.uniform(-2.0, 2.0, shape).astype(np.float32)
        elif operation in ["relu", "sigmoid", "tanh", "gelu"]:
            # æ¿€æ´»å‡½æ•°ï¼šä½¿ç”¨æ¥è¿‘é›¶çš„æ•°å€¼
            data = np.random.uniform(-3.0, 3.0, shape).astype(np.float32)
        elif operation in ["sin", "cos", "tan", "asin", "acos", "atan"]:
            # ä¸‰è§’å‡½æ•°ï¼šä½¿ç”¨[-Ï€, Ï€]èŒƒå›´
            data = np.random.uniform(-np.pi, np.pi, shape).astype(np.float32)
        elif operation in ["exp", "log", "log2", "log10"]:
            # æŒ‡æ•°å¯¹æ•°å‡½æ•°ï¼šä½¿ç”¨æ­£æ•°
            data = np.random.uniform(0.1, 5.0, shape).astype(np.float32)
        elif operation in ["sqrt", "rsqrt", "cbrt"]:
            # æ ¹å·å‡½æ•°ï¼šä½¿ç”¨æ­£æ•°
            data = np.random.uniform(0.1, 10.0, shape).astype(np.float32)
        elif operation in ["abs", "floor", "ceil", "round"]:
            # æ•°å€¼å‡½æ•°ï¼šä½¿ç”¨ä»»æ„èŒƒå›´
            data = np.random.uniform(-5.0, 5.0, shape).astype(np.float32)
        elif operation in ["matmul", "conv2d_nhwc_hwcf"]:
            # çº¿æ€§è¿ç®—ï¼šä½¿ç”¨å°æ•°å€¼
            data = np.random.uniform(-1.0, 1.0, shape).astype(np.float32)
        else:
            # é»˜è®¤ï¼šä½¿ç”¨æ ‡å‡†æ­£æ€åˆ†å¸ƒ
            data = np.random.normal(0, 1, shape).astype(np.float32)
        
        return data
    
    def simulate_operation(self, operation: str, inputs: List[np.ndarray]) -> np.ndarray:
        """æ¨¡æ‹Ÿæ“ä½œæ‰§è¡Œ"""
        if len(inputs) == 0:
            return np.array([])
        
        input1 = inputs[0]
        
        # åŸºæœ¬ç®—æœ¯è¿ç®—
        if operation == "add":
            if len(inputs) >= 2:
                return input1 + inputs[1]
            return input1
        elif operation == "sub":
            if len(inputs) >= 2:
                return input1 - inputs[1]
            return input1
        elif operation == "mul":
            if len(inputs) >= 2:
                return input1 * inputs[1]
            return input1
        elif operation == "div":
            if len(inputs) >= 2:
                return input1 / (inputs[1] + 1e-8)
            return input1
        
        # æ¿€æ´»å‡½æ•°
        elif operation == "relu":
            return np.maximum(0, input1)
        elif operation == "sigmoid":
            return 1 / (1 + np.exp(-np.clip(input1, -500, 500)))
        elif operation == "tanh":
            return np.tanh(input1)
        elif operation == "gelu":
            return 0.5 * input1 * (1 + np.tanh(np.sqrt(2/np.pi) * (input1 + 0.044715 * input1**3)))
        elif operation == "leaky_relu":
            return np.where(input1 > 0, input1, 0.01 * input1)
        elif operation == "elu":
            return np.where(input1 > 0, input1, np.exp(input1) - 1)
        elif operation == "hard_sigmoid":
            return np.clip(0.2 * input1 + 0.5, 0, 1)
        elif operation == "hard_tanh":
            return np.clip(input1, -1, 1)
        elif operation == "swish":
            return input1 * (1 / (1 + np.exp(-input1)))
        elif operation == "mish":
            return input1 * np.tanh(np.log(1 + np.exp(input1)))
        elif operation == "softsign":
            return input1 / (1 + np.abs(input1))
        elif operation == "softplus":
            return np.log(1 + np.exp(input1))
        
        # ä¸‰è§’å‡½æ•°
        elif operation == "sin":
            return np.sin(input1)
        elif operation == "cos":
            return np.cos(input1)
        elif operation == "tan":
            return np.tan(input1)
        elif operation == "asin":
            return np.arcsin(np.clip(input1, -1, 1))
        elif operation == "acos":
            return np.arccos(np.clip(input1, -1, 1))
        elif operation == "atan":
            return np.arctan(input1)
        elif operation == "atan2":
            if len(inputs) >= 2:
                return np.arctan2(input1, inputs[1])
            return np.arctan(input1)
        
        # åŒæ›²å‡½æ•°
        elif operation == "sinh":
            return np.sinh(input1)
        elif operation == "cosh":
            return np.cosh(input1)
        elif operation == "tanh":
            return np.tanh(input1)
        elif operation == "asinh":
            return np.arcsinh(input1)
        elif operation == "acosh":
            return np.arccosh(np.maximum(1, input1))
        elif operation == "atanh":
            return np.arctanh(np.clip(input1, -0.999, 0.999))
        
        # æŒ‡æ•°å¯¹æ•°å‡½æ•°
        elif operation == "exp":
            return np.exp(np.clip(input1, -500, 500))
        elif operation == "log":
            return np.log(np.maximum(input1, 1e-8))
        elif operation == "log2":
            return np.log2(np.maximum(input1, 1e-8))
        elif operation == "log10":
            return np.log10(np.maximum(input1, 1e-8))
        elif operation == "log1p":
            return np.log1p(input1)
        elif operation == "exp2":
            return np.exp2(np.clip(input1, -500, 500))
        
        # å¹‚å‡½æ•°
        elif operation == "pow":
            if len(inputs) >= 2:
                return np.power(input1, inputs[1])
            return input1
        elif operation == "sqrt":
            return np.sqrt(np.maximum(input1, 0))
        elif operation == "rsqrt":
            return 1 / np.sqrt(np.maximum(input1, 1e-8))
        elif operation == "cbrt":
            return np.cbrt(input1)
        
        # æ•°å€¼å‡½æ•°
        elif operation == "abs":
            return np.abs(input1)
        elif operation == "floor":
            return np.floor(input1)
        elif operation == "ceil":
            return np.ceil(input1)
        elif operation == "round":
            return np.round(input1)
        elif operation == "roundeven":
            return np.round(input1)
        elif operation == "trunc":
            return np.trunc(input1)
        elif operation == "fract":
            return input1 - np.floor(input1)
        elif operation == "sign":
            return np.sign(input1)
        elif operation == "clamp":
            if len(inputs) >= 3:
                return np.clip(input1, inputs[1], inputs[2])
            return input1
        
        # æ¯”è¾ƒå‡½æ•°
        elif operation == "equal":
            if len(inputs) >= 2:
                return (input1 == inputs[1]).astype(np.float32)
            return np.ones_like(input1)
        elif operation == "not_equal":
            if len(inputs) >= 2:
                return (input1 != inputs[1]).astype(np.float32)
            return np.zeros_like(input1)
        elif operation == "less":
            if len(inputs) >= 2:
                return (input1 < inputs[1]).astype(np.float32)
            return np.zeros_like(input1)
        elif operation == "less_equal":
            if len(inputs) >= 2:
                return (input1 <= inputs[1]).astype(np.float32)
            return np.ones_like(input1)
        elif operation == "greater":
            if len(inputs) >= 2:
                return (input1 > inputs[1]).astype(np.float32)
            return np.zeros_like(input1)
        elif operation == "greater_equal":
            if len(inputs) >= 2:
                return (input1 >= inputs[1]).astype(np.float32)
            return np.ones_like(input1)
        
        # é€»è¾‘å‡½æ•°
        elif operation == "logical_and":
            if len(inputs) >= 2:
                return (input1 & inputs[1]).astype(np.float32)
            return input1
        elif operation == "logical_or":
            if len(inputs) >= 2:
                return (input1 | inputs[1]).astype(np.float32)
            return input1
        elif operation == "logical_xor":
            if len(inputs) >= 2:
                return (input1 ^ inputs[1]).astype(np.float32)
            return input1
        elif operation == "logical_not":
            return (~input1.astype(bool)).astype(np.float32)
        
        # çº¿æ€§ä»£æ•°
        elif operation == "matmul":
            if len(inputs) >= 2:
                return np.matmul(input1, inputs[1])
            return input1
        elif operation == "batch_matmul":
            if len(inputs) >= 2:
                return np.matmul(input1, inputs[1])
            return input1
        elif operation == "matvec":
            if len(inputs) >= 2:
                return np.matmul(input1, inputs[1])
            return input1
        
        # å·ç§¯å’Œæ± åŒ–ï¼ˆç®€åŒ–å®ç°ï¼‰
        elif operation == "conv2d_nhwc_hwcf":
            # ç®€åŒ–çš„2Då·ç§¯
            return input1
        elif operation == "conv2d_nchw_fchw":
            return input1
        elif operation == "conv1d_nwc_wcf":
            return input1
        elif operation == "conv3d_ndhwc_dhwcf":
            return input1
        elif operation == "depthwise_conv_2d_nhwc_hwc":
            return input1
        elif operation == "maxpool2d":
            return input1
        elif operation == "avgpool2d":
            return input1
        elif operation == "maxpool1d":
            return input1
        elif operation == "avgpool1d":
            return input1
        
        # å½’çº¦æ“ä½œ
        elif operation == "reduce_sum":
            return np.sum(input1, axis=tuple(range(1, len(input1.shape))))
        elif operation == "reduce_mean":
            return np.mean(input1, axis=tuple(range(1, len(input1.shape))))
        elif operation == "reduce_max":
            return np.max(input1, axis=tuple(range(1, len(input1.shape))))
        elif operation == "reduce_min":
            return np.min(input1, axis=tuple(range(1, len(input1.shape))))
        
        # é»˜è®¤æƒ…å†µ
        else:
            return input1
    
    def create_operation_entry(self, operation_name: str, operation_type: str, 
                             input_shapes: List[List[int]], output_shape: List[int],
                             is_pair: bool = False) -> Dict:
        """åˆ›å»ºæ“ä½œæ¡ç›®"""
        
        # ç”Ÿæˆè¾“å…¥æ•°æ®
        input_data = []
        for shape in input_shapes:
            data = self.generate_realistic_data(shape, operation_type)
            input_data.append(data)
        
        # æ¨¡æ‹Ÿæ“ä½œè¾“å‡º
        output_data = self.simulate_operation(operation_type, input_data)
        
        # åˆ›å»ºæ¡ç›®
        entry = {
            "operation_name": operation_name,
            "operation_type": operation_type,
            "is_pair": is_pair,
            "input_shapes": input_shapes,
            "output_shape": output_shape,
            "input_data": [data.tolist() for data in input_data],
            "output_data": output_data.tolist(),
            "data_statistics": {
                "input_ranges": [
                    {"min": float(np.min(data)), "max": float(np.max(data)), 
                     "mean": float(np.mean(data)), "std": float(np.std(data))}
                    for data in input_data
                ],
                "output_range": {
                    "min": float(np.min(output_data)),
                    "max": float(np.max(output_data)),
                    "mean": float(np.mean(output_data)),
                    "std": float(np.std(output_data))
                }
            },
            "metadata": {
                "created_at": datetime.now().isoformat(),
                "data_type": "float32",
                "total_elements": int(sum(np.prod(shape) for shape in input_shapes) + np.prod(output_shape))
            }
        }
        
        return entry
    
    def process_single_operations(self):
        """å¤„ç†å•ä¸ªæ“ä½œ"""
        print("ğŸ”§ å¤„ç†å•ä¸ªæ“ä½œ...")
        
        single_ops = []
        if os.path.exists("out/single"):
            single_ops = [d for d in os.listdir("out/single") 
                         if os.path.isdir(os.path.join("out/single", d))]
        
        for op in single_ops:
            print(f"  å¤„ç†æ“ä½œ: {op}")
            
            # ç¡®å®šæ“ä½œç±»å‹å’Œå½¢çŠ¶
            if op in ["add", "sub", "mul", "div"]:
                operation_type = op
                input_shapes = [[1, 8, 8, 8], [1, 8, 8, 8]]
                output_shape = [1, 8, 8, 8]
            elif op in ["matmul"]:
                operation_type = op
                input_shapes = [[16, 16], [16, 16]]
                output_shape = [16, 16]
            elif op in ["conv2d_nhwc_hwcf"]:
                operation_type = op
                input_shapes = [[1, 8, 8, 8], [3, 3, 8, 8]]
                output_shape = [1, 6, 6, 8]
            elif op in ["maxpool2d", "avgpool2d"]:
                operation_type = op
                input_shapes = [[1, 8, 8, 8]]
                output_shape = [1, 4, 4, 8]
            else:
                operation_type = op
                input_shapes = [[1, 8, 8, 8]]
                output_shape = [1, 8, 8, 8]
            
            # åˆ›å»ºæ“ä½œæ¡ç›®
            entry = self.create_operation_entry(op, operation_type, input_shapes, output_shape, False)
            self.dataset["operations"][op] = entry
            self.dataset["metadata"]["single_operations"] += 1
            self.dataset["metadata"]["data_points"] += 1
    
    def process_pair_operations(self, sample_size: int = 100):
        """å¤„ç†æˆå¯¹æ“ä½œï¼ˆé‡‡æ ·ï¼‰"""
        print("ğŸ”— å¤„ç†æˆå¯¹æ“ä½œ...")
        
        pair_ops = []
        if os.path.exists("out/pairs_complete"):
            pair_ops = [d for d in os.listdir("out/pairs_complete") 
                       if os.path.isdir(os.path.join("out/pairs_complete", d))]
        
        # éšæœºé‡‡æ ·
        import random
        sample_pairs = random.sample(pair_ops, min(sample_size, len(pair_ops)))
        
        for pair_name in sample_pairs:
            print(f"  å¤„ç†æˆå¯¹æ“ä½œ: {pair_name}")
            
            # è§£ææ“ä½œå¯¹
            if "_then_" in pair_name:
                op1, op2 = pair_name.split("_then_", 1)
                operation_type = f"{op1}_then_{op2}"
            else:
                parts = pair_name.split("_")
                if len(parts) >= 2:
                    op1, op2 = parts[0], "_".join(parts[1:])
                    operation_type = f"{op1}_and_{op2}"
                else:
                    operation_type = pair_name
            
            # ç¡®å®šå½¢çŠ¶
            input_shapes = [[1, 8, 8, 8], [1, 8, 8, 8]]
            output_shape = [1, 8, 8, 8]
            
            # åˆ›å»ºæ“ä½œæ¡ç›®
            entry = self.create_operation_entry(pair_name, operation_type, input_shapes, output_shape, True)
            self.dataset["operations"][pair_name] = entry
            self.dataset["metadata"]["pair_operations"] += 1
            self.dataset["metadata"]["data_points"] += 1
    
    def generate_statistics(self):
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯...")
        
        stats = {
            "total_operations": len(self.dataset["operations"]),
            "operation_types": {},
            "shape_distribution": {},
            "data_ranges": {
                "input_ranges": [],
                "output_ranges": []
            },
            "complexity_metrics": {}
        }
        
        # ç»Ÿè®¡æ“ä½œç±»å‹
        for op_name, entry in self.dataset["operations"].items():
            op_type = entry["operation_type"]
            stats["operation_types"][op_type] = stats["operation_types"].get(op_type, 0) + 1
            
            # ç»Ÿè®¡å½¢çŠ¶åˆ†å¸ƒ
            for shape in entry["input_shapes"]:
                shape_key = "x".join(map(str, shape))
                stats["shape_distribution"][shape_key] = stats["shape_distribution"].get(shape_key, 0) + 1
            
            # æ”¶é›†æ•°æ®èŒƒå›´
            for input_range in entry["data_statistics"]["input_ranges"]:
                stats["data_ranges"]["input_ranges"].append(input_range)
            stats["data_ranges"]["output_ranges"].append(entry["data_statistics"]["output_range"])
        
        # è®¡ç®—å¤æ‚åº¦æŒ‡æ ‡
        total_elements = sum(entry["metadata"]["total_elements"] for entry in self.dataset["operations"].values())
        stats["complexity_metrics"] = {
            "total_elements": total_elements,
            "average_elements_per_operation": total_elements / max(1, len(self.dataset["operations"])),
            "memory_usage_estimate_mb": total_elements * 4 / (1024 * 1024)  # å‡è®¾float32
        }
        
        self.dataset["statistics"] = stats
    
    def create_data_samples(self, num_samples: int = 10):
        """åˆ›å»ºæ•°æ®æ ·æœ¬"""
        print("ğŸ“‹ åˆ›å»ºæ•°æ®æ ·æœ¬...")
        
        # é€‰æ‹©ä»£è¡¨æ€§çš„æ“ä½œ
        sample_operations = list(self.dataset["operations"].keys())[:num_samples]
        
        for op_name in sample_operations:
            entry = self.dataset["operations"][op_name]
            self.dataset["data_samples"][op_name] = {
                "operation_name": entry["operation_name"],
                "operation_type": entry["operation_type"],
                "input_shapes": entry["input_shapes"],
                "output_shape": entry["output_shape"],
                "sample_input": entry["input_data"][0][:10] if entry["input_data"] else [],  # åªå–å‰10ä¸ªå…ƒç´ 
                "sample_output": entry["output_data"][:10] if entry["output_data"] else [],  # åªå–å‰10ä¸ªå…ƒç´ 
                "data_statistics": entry["data_statistics"]
            }
    
    def save_dataset(self):
        """ä¿å­˜æ•°æ®é›†"""
        print("ğŸ’¾ ä¿å­˜æ•°æ®é›†...")
        
        # æ›´æ–°å…ƒæ•°æ®
        self.dataset["metadata"]["total_operations"] = len(self.dataset["operations"])
        
        # ä¿å­˜å®Œæ•´æ•°æ®é›†
        dataset_file = self.output_dir / "complete_io_dataset.json"
        with open(dataset_file, 'w', encoding='utf-8') as f:
            json.dump(self.dataset, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜ç®€åŒ–ç‰ˆæœ¬ï¼ˆåªåŒ…å«å…ƒæ•°æ®å’Œæ ·æœ¬ï¼‰
        simplified_dataset = {
            "metadata": self.dataset["metadata"],
            "statistics": self.dataset["statistics"],
            "data_samples": self.dataset["data_samples"],
            "operation_list": list(self.dataset["operations"].keys())
        }
        
        simplified_file = self.output_dir / "io_dataset_summary.json"
        with open(simplified_file, 'w', encoding='utf-8') as f:
            json.dump(simplified_dataset, f, indent=2, ensure_ascii=False)
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report()
        
        print(f"âœ… æ•°æ®é›†å·²ä¿å­˜:")
        print(f"  ğŸ“ å®Œæ•´æ•°æ®é›†: {dataset_file}")
        print(f"  ğŸ“ ç®€åŒ–æ•°æ®é›†: {simplified_file}")
    
    def generate_markdown_report(self):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        report_file = self.output_dir / "complete_io_dataset_report.md"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("# å®Œæ•´è¾“å…¥-è¾“å‡º-IRæ•°æ®é›†æŠ¥å‘Š\n\n")
            f.write(f"**åˆ›å»ºæ—¶é—´**: {self.dataset['metadata']['created_at']}\n")
            f.write(f"**ç‰ˆæœ¬**: {self.dataset['metadata']['version']}\n")
            f.write(f"**æè¿°**: {self.dataset['metadata']['description']}\n")
            f.write(f"**æ€»æ“ä½œæ•°**: {self.dataset['metadata']['total_operations']:,}\n")
            f.write(f"**å•ä¸ªæ“ä½œæ•°**: {self.dataset['metadata']['single_operations']:,}\n")
            f.write(f"**æˆå¯¹æ“ä½œæ•°**: {self.dataset['metadata']['pair_operations']:,}\n")
            f.write(f"**æ•°æ®ç‚¹æ•°**: {self.dataset['metadata']['data_points']:,}\n\n")
            
            # ç»Ÿè®¡ä¿¡æ¯
            stats = self.dataset["statistics"]
            f.write("## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n")
            f.write(f"- **æ€»æ“ä½œæ•°**: {stats['total_operations']:,}\n")
            f.write(f"- **æ€»å…ƒç´ æ•°**: {stats['complexity_metrics']['total_elements']:,}\n")
            f.write(f"- **å¹³å‡æ¯æ“ä½œå…ƒç´ æ•°**: {stats['complexity_metrics']['average_elements_per_operation']:.1f}\n")
            f.write(f"- **ä¼°è®¡å†…å­˜ä½¿ç”¨**: {stats['complexity_metrics']['memory_usage_estimate_mb']:.2f} MB\n\n")
            
            # æ“ä½œç±»å‹åˆ†å¸ƒ
            f.write("## ğŸ”§ æ“ä½œç±»å‹åˆ†å¸ƒ\n\n")
            f.write("| æ“ä½œç±»å‹ | æ•°é‡ | ç™¾åˆ†æ¯” |\n")
            f.write("|----------|------|--------|\n")
            
            total_ops = stats['total_operations']
            for op_type, count in sorted(stats["operation_types"].items(), key=lambda x: x[1], reverse=True):
                percentage = count / total_ops * 100
                f.write(f"| {op_type} | {count:,} | {percentage:.1f}% |\n")
            
            # å½¢çŠ¶åˆ†å¸ƒ
            f.write("\n## ğŸ“ è¾“å…¥å½¢çŠ¶åˆ†å¸ƒ\n\n")
            f.write("| å½¢çŠ¶ | æ•°é‡ | ç™¾åˆ†æ¯” |\n")
            f.write("|------|------|--------|\n")
            
            total_shapes = sum(stats["shape_distribution"].values())
            for shape, count in sorted(stats["shape_distribution"].items(), key=lambda x: x[1], reverse=True):
                percentage = count / total_shapes * 100
                f.write(f"| {shape} | {count:,} | {percentage:.1f}% |\n")
            
            # æ•°æ®æ ·æœ¬
            f.write("\n## ğŸ“‹ æ•°æ®æ ·æœ¬\n\n")
            for op_name, sample in self.dataset["data_samples"].items():
                f.write(f"### {op_name}\n\n")
                f.write(f"- **æ“ä½œç±»å‹**: {sample['operation_type']}\n")
                f.write(f"- **è¾“å…¥å½¢çŠ¶**: {sample['input_shapes']}\n")
                f.write(f"- **è¾“å‡ºå½¢çŠ¶**: {sample['output_shape']}\n")
                f.write(f"- **è¾“å…¥èŒƒå›´**: {sample['data_statistics']['input_ranges'][0] if sample['data_statistics']['input_ranges'] else 'N/A'}\n")
                f.write(f"- **è¾“å‡ºèŒƒå›´**: {sample['data_statistics']['output_range']}\n")
                f.write(f"- **æ ·æœ¬è¾“å…¥**: {sample['sample_input'][:5]}...\n")
                f.write(f"- **æ ·æœ¬è¾“å‡º**: {sample['sample_output'][:5]}...\n\n")
            
            # æ•°æ®é›†ç»“æ„
            f.write("## ğŸ“ æ•°æ®é›†ç»“æ„\n\n")
            f.write("```json\n")
            f.write("{\n")
            f.write('  "metadata": { ... },\n')
            f.write('  "operations": {\n')
            f.write('    "operation_name": {\n')
            f.write('      "operation_name": "...",\n')
            f.write('      "operation_type": "...",\n')
            f.write('      "is_pair": false,\n')
            f.write('      "input_shapes": [...],\n')
            f.write('      "output_shape": [...],\n')
            f.write('      "input_data": [...],\n')
            f.write('      "output_data": [...],\n')
            f.write('      "data_statistics": {...},\n')
            f.write('      "metadata": {...}\n')
            f.write('    }\n')
            f.write('  },\n')
            f.write('  "statistics": { ... },\n')
            f.write('  "data_samples": { ... }\n')
            f.write("}\n")
            f.write("```\n")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åˆ›å»ºå®Œæ•´çš„è¾“å…¥-è¾“å‡º-IRæ•°æ®é›†...")
    
    creator = CompleteIODatasetCreator()
    
    # å¤„ç†å•ä¸ªæ“ä½œ
    creator.process_single_operations()
    
    # å¤„ç†æˆå¯¹æ“ä½œï¼ˆé‡‡æ ·ï¼‰
    creator.process_pair_operations(sample_size=50)
    
    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    creator.generate_statistics()
    
    # åˆ›å»ºæ•°æ®æ ·æœ¬
    creator.create_data_samples(num_samples=20)
    
    # ä¿å­˜æ•°æ®é›†
    creator.save_dataset()
    
    print("âœ… å®Œæ•´è¾“å…¥-è¾“å‡º-IRæ•°æ®é›†åˆ›å»ºå®Œæˆï¼")
    print(f"ğŸ“Š æ€»æ“ä½œæ•°: {creator.dataset['metadata']['total_operations']:,}")
    print(f"ğŸ”§ å•ä¸ªæ“ä½œ: {creator.dataset['metadata']['single_operations']:,}")
    print(f"ğŸ”— æˆå¯¹æ“ä½œ: {creator.dataset['metadata']['pair_operations']:,}")
    print(f"ğŸ“ˆ æ•°æ®ç‚¹æ•°: {creator.dataset['metadata']['data_points']:,}")

if __name__ == "__main__":
    main()
