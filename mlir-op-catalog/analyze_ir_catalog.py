#!/usr/bin/env python3
"""
åˆ†æIRç›®å½•ï¼Œç”Ÿæˆè¯¦ç»†çš„åˆ†ç±»ç»Ÿè®¡
"""

import os
import json
from collections import defaultdict, Counter
from pathlib import Path

def analyze_ir_catalog():
    """åˆ†æIRç›®å½•ç»“æ„"""
    print("ğŸ” åˆ†æIRç›®å½•ç»“æ„...")
    
    # ç»Ÿè®¡å„ä¸ªç›®å½•çš„æ–‡ä»¶æ•°é‡
    directories = {
        'single': 'out/single',
        'single_llvm': 'out/single_llvm', 
        'single_complete': 'out/single_complete',
        'single_complete_llvm': 'out/single_complete_llvm',
        'pairs': 'out/pairs',
        'pairs_llvm': 'out/pairs_llvm',
        'pairs_complete': 'out/pairs_complete',
        'pairs_complete_llvm': 'out/pairs_complete_llvm'
    }
    
    stats = {}
    total_mlir = 0
    total_llvm = 0
    
    for name, path in directories.items():
        if os.path.exists(path):
            mlir_count = len([f for f in os.listdir(path) if f.endswith('.mlir')]) if os.path.isdir(path) else 0
            llvm_count = len([f for f in os.listdir(path) if f.endswith('.ll')]) if os.path.isdir(path) else 0
            
            # é€’å½’ç»Ÿè®¡å­ç›®å½•
            if os.path.isdir(path):
                for root, dirs, files in os.walk(path):
                    mlir_count += len([f for f in files if f.endswith('.mlir')])
                    llvm_count += len([f for f in files if f.endswith('.ll')])
            
            stats[name] = {
                'mlir_files': mlir_count,
                'llvm_files': llvm_count,
                'total_files': mlir_count + llvm_count
            }
            
            if 'mlir' in name:
                total_mlir += mlir_count
            if 'llvm' in name:
                total_llvm += llvm_count
        else:
            stats[name] = {'mlir_files': 0, 'llvm_files': 0, 'total_files': 0}
    
    # åˆ†ææ“ä½œç±»å‹
    print("ğŸ”§ åˆ†ææ“ä½œç±»å‹...")
    operation_types = defaultdict(int)
    tensor_shapes = defaultdict(int)
    
    # æ‰«æå•ä¸ªæ“ä½œ
    single_ops = []
    if os.path.exists('out/single'):
        for item in os.listdir('out/single'):
            if os.path.isdir(os.path.join('out/single', item)):
                single_ops.append(item)
    
    # æ‰«ææˆå¯¹æ“ä½œ
    pair_ops = []
    if os.path.exists('out/pairs_llvm'):
        for item in os.listdir('out/pairs_llvm'):
            if os.path.isdir(os.path.join('out/pairs_llvm', item)):
                pair_ops.append(item)
    
    # åˆ†ætensorå½¢çŠ¶
    shape_patterns = [
        '1x8x8x8xf32',  # 4D tensor
        '16x16xf32',    # 2D tensor  
        '3x3x8x8xf32',  # 4D kernel
        '1x6x6x8xf32',  # 4D output
        '1x4x4x8xf32',  # 4D output
        '1x8xf32'       # 1D tensor
    ]
    
    for pattern in shape_patterns:
        tensor_shapes[pattern] = 0
    
    # ç”ŸæˆæŠ¥å‘Š
    report = {
        'summary': {
            'total_mlir_files': total_mlir,
            'total_llvm_files': total_llvm,
            'total_files': total_mlir + total_llvm,
            'single_operations': len(single_ops),
            'pair_operations': len(pair_ops)
        },
        'directory_stats': stats,
        'operation_catalog': {
            'single_operations': single_ops,
            'pair_operations': pair_ops[:20]  # åªæ˜¾ç¤ºå‰20ä¸ª
        },
        'tensor_shapes': dict(tensor_shapes)
    }
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    with open('ir_catalog_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ç”ŸæˆMarkdownæŠ¥å‘Š
    generate_catalog_report(report)
    
    return report

def generate_catalog_report(report):
    """ç”Ÿæˆç›®å½•æŠ¥å‘Š"""
    with open('IRç›®å½•ç»Ÿè®¡æŠ¥å‘Š.md', 'w', encoding='utf-8') as f:
        f.write("# IRç›®å½•ç»Ÿè®¡æŠ¥å‘Š\n\n")
        
        # æ€»ä½“ç»Ÿè®¡
        f.write("## ğŸ“Š æ€»ä½“ç»Ÿè®¡\n\n")
        f.write(f"- **æ€»MLIRæ–‡ä»¶**: {report['summary']['total_mlir_files']:,}\n")
        f.write(f"- **æ€»LLVMæ–‡ä»¶**: {report['summary']['total_llvm_files']:,}\n")
        f.write(f"- **æ€»æ–‡ä»¶æ•°**: {report['summary']['total_files']:,}\n")
        f.write(f"- **å•ä¸ªæ“ä½œæ•°**: {report['summary']['single_operations']}\n")
        f.write(f"- **æˆå¯¹æ“ä½œæ•°**: {report['summary']['pair_operations']}\n\n")
        
        # ç›®å½•ç»Ÿè®¡
        f.write("## ğŸ“ ç›®å½•ç»Ÿè®¡\n\n")
        f.write("| ç›®å½• | MLIRæ–‡ä»¶ | LLVMæ–‡ä»¶ | æ€»æ–‡ä»¶æ•° |\n")
        f.write("|------|----------|----------|----------|\n")
        
        for name, stats in report['directory_stats'].items():
            f.write(f"| {name} | {stats['mlir_files']:,} | {stats['llvm_files']:,} | {stats['total_files']:,} |\n")
        
        f.write("\n")
        
        # æ“ä½œç±»å‹
        f.write("## ğŸ”§ æ“ä½œç±»å‹\n\n")
        f.write("### å•ä¸ªæ“ä½œ (å‰20ä¸ª)\n\n")
        for i, op in enumerate(report['operation_catalog']['single_operations'][:20], 1):
            f.write(f"{i}. **{op}**\n")
        
        if len(report['operation_catalog']['single_operations']) > 20:
            f.write(f"\n... è¿˜æœ‰ {len(report['operation_catalog']['single_operations']) - 20} ä¸ªæ“ä½œ\n")
        
        f.write("\n### æˆå¯¹æ“ä½œ (å‰20ä¸ª)\n\n")
        for i, op in enumerate(report['operation_catalog']['pair_operations'], 1):
            f.write(f"{i}. **{op}**\n")
        
        if report['summary']['pair_operations'] > 20:
            f.write(f"\n... è¿˜æœ‰ {report['summary']['pair_operations'] - 20} ä¸ªæ“ä½œ\n")
        
        # æ–‡ä»¶å¤§å°ç»Ÿè®¡
        f.write("\n## ğŸ’¾ æ–‡ä»¶å¤§å°ç»Ÿè®¡\n\n")
        f.write("```bash\n")
        f.write("# å„ç›®å½•å¤§å°\n")
        for name in report['directory_stats'].keys():
            if os.path.exists(f"out/{name}"):
                f.write(f"du -sh out/{name}\n")
        f.write("```\n\n")
        
        # å®éªŒå»ºè®®
        f.write("## ğŸ§ª å®éªŒå»ºè®®\n\n")
        f.write("### æŒ‰å¤æ‚åº¦åˆ†ç±»\n\n")
        f.write("1. **ç®€å•æ“ä½œ** (1x8x8x8xf32):\n")
        f.write("   - å…ƒç´ çº§è¿ç®—: add, sub, mul, div\n")
        f.write("   - æ¿€æ´»å‡½æ•°: relu, sigmoid, tanh\n")
        f.write("   - æ•°å­¦å‡½æ•°: exp, log, sqrt\n\n")
        
        f.write("2. **ä¸­ç­‰æ“ä½œ** (16x16xf32):\n")
        f.write("   - çŸ©é˜µä¹˜æ³•: matmul\n")
        f.write("   - çº¿æ€§ä»£æ•°è¿ç®—\n\n")
        
        f.write("3. **å¤æ‚æ“ä½œ** (å¤šå½¢çŠ¶):\n")
        f.write("   - å·ç§¯: conv2d_nhwc_hwcf\n")
        f.write("   - æ± åŒ–: maxpool2d, avgpool2d\n")
        f.write("   - æˆå¯¹æ“ä½œç»„åˆ\n\n")
        
        f.write("### å®éªŒåˆ†ç»„\n\n")
        f.write("1. **åŸºç¡€è¿ç®—ç»„**: æ•°å­¦è¿ç®— + æ¿€æ´»å‡½æ•°\n")
        f.write("2. **çº¿æ€§ä»£æ•°ç»„**: çŸ©é˜µè¿ç®— + å·ç§¯\n")
        f.write("3. **ç»„åˆè¿ç®—ç»„**: æˆå¯¹æ“ä½œæµ‹è¯•\n")
        f.write("4. **å®Œæ•´æµ‹è¯•ç»„**: æ‰€æœ‰æ“ä½œçš„ç»¼åˆæµ‹è¯•\n\n")
        
        f.write("### æ•°æ®æ ¼å¼\n\n")
        f.write("æ‰€æœ‰IRæ–‡ä»¶éƒ½ä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼š\n")
        f.write("- **MLIR**: ä½¿ç”¨linalgæ–¹è¨€\n")
        f.write("- **LLVM IR**: æ ‡å‡†LLVM IRæ ¼å¼\n")
        f.write("- **è¾“å…¥è¾“å‡º**: ç»Ÿä¸€çš„tensoræ ¼å¼\n\n")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†æIRç›®å½•...")
    
    # åˆ†æç›®å½•
    report = analyze_ir_catalog()
    
    print("âœ… åˆ†æå®Œæˆï¼")
    print(f"ğŸ“Š æ€»æ–‡ä»¶æ•°: {report['summary']['total_files']:,}")
    print(f"ğŸ”§ å•ä¸ªæ“ä½œ: {report['summary']['single_operations']}")
    print(f"ğŸ”— æˆå¯¹æ“ä½œ: {report['summary']['pair_operations']}")
    print(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Š: IRç›®å½•ç»Ÿè®¡æŠ¥å‘Š.md")
    print(f"ğŸ“„ æ•°æ®æ–‡ä»¶: ir_catalog_analysis.json")

if __name__ == "__main__":
    main()
