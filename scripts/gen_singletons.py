#!/usr/bin/env python3
"""
å•ä¸ªæ“ä½œMLIRç”Ÿæˆè„šæœ¬
ç”Ÿæˆå•ä¸ªæ“ä½œçš„MLIRæ–‡ä»¶
"""

import json
import os
import yaml
from pathlib import Path
from jinja2 import Environment, FileSystemLoader
from typing import Dict, Any, List

def load_cases(cases_file: Path) -> List[Dict[str, Any]]:
    """åŠ è½½æ“ä½œå®ä¾‹"""
    with open(cases_file, 'r') as f:
        return json.load(f)

def load_ops_config(config_file: Path) -> Dict[str, Any]:
    """åŠ è½½æ“ä½œé…ç½®"""
    with open(config_file, 'r') as f:
        return yaml.safe_load(f)

def setup_jinja_env(template_dir: Path) -> Environment:
    """è®¾ç½®Jinja2ç¯å¢ƒ"""
    env = Environment(
        loader=FileSystemLoader(template_dir),
        trim_blocks=True,
        lstrip_blocks=True
    )
    return env

def generate_simple_elementwise_mlir(case: Dict[str, Any]) -> str:
    """ç”Ÿæˆç®€å•çš„å…ƒç´ çº§æ“ä½œMLIR"""
    params = case['params']
    op_id = case['op_id']
    
    # åŸºæœ¬å½¢çŠ¶å‚æ•°
    N, H, W, C = params['N'], params['H'], params['W'], params['C']
    dtype = params['dtype']
    
    # æ ¹æ®æ“ä½œç±»å‹ç”Ÿæˆä¸åŒçš„MLIRå†…å®¹
    if op_id == 'relu':
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %cst0 = arith.constant 0.0 : {dtype}
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x : tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %out: {dtype}):
        %max = arith.maximumf %x_val, %cst0 : {dtype}
        linalg.yield %max : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""
    
    elif op_id == 'exp':
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x : tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %out: {dtype}):
        %exp = math.exp %x_val : {dtype}
        linalg.yield %exp : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""
    
    elif op_id == 'tanh':
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x : tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %out: {dtype}):
        %tanh = math.tanh %x_val : {dtype}
        linalg.yield %tanh : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""
    
    elif op_id == 'sigmoid':
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %cst_neg1 = arith.constant -1.0 : {dtype}
    %cst1 = arith.constant 1.0 : {dtype}
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x : tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %out: {dtype}):
        %neg_x = arith.mulf %x_val, %cst_neg1 : {dtype}
        %exp_neg_x = math.exp %neg_x : {dtype}
        %denom = arith.addf %cst1, %exp_neg_x : {dtype}
        %sigmoid = arith.divf %cst1, %denom : {dtype}
        linalg.yield %sigmoid : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""
    
    elif op_id in ['add', 'sub', 'mul', 'div']:
        # äºŒå…ƒæ“ä½œ
        if op_id == 'add':
            op = 'addf'
        elif op_id == 'sub':
            op = 'subf'
        elif op_id == 'mul':
            op = 'mulf'
        elif op_id == 'div':
            op = 'divf'
        
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>, %y: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x, %y : tensor<{N}x{H}x{W}x{C}x{dtype}>, tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %y_val: {dtype}, %out: {dtype}):
        %res = arith.{op} %x_val, %y_val : {dtype}
        linalg.yield %res : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""
    
    else:
        # é»˜è®¤æ“ä½œ - ç®€å•çš„åŠ æ³•
        return f"""module {{
  func.func @main(%x: tensor<{N}x{H}x{W}x{C}x{dtype}>) -> tensor<{N}x{H}x{W}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    %result = linalg.generic {{
      indexing_maps = [
        affine_map<(i, j, k, l) -> (i, j, k, l)>,
        affine_map<(i, j, k, l) -> (i, j, k, l)>
      ],
      iterator_types = ["parallel", "parallel", "parallel", "parallel"]
    }} ins(%x : tensor<{N}x{H}x{W}x{C}x{dtype}>) 
        outs(%init : tensor<{N}x{H}x{W}x{C}x{dtype}>) {{
      ^bb0(%x_val: {dtype}, %out: {dtype}):
        %res = arith.addf %x_val, %x_val : {dtype}
        linalg.yield %res : {dtype}
    }} -> tensor<{N}x{H}x{W}x{C}x{dtype}>
    
    return %result : tensor<{N}x{H}x{W}x{C}x{dtype}>
  }}
}}"""

def generate_matmul_mlir(case: Dict[str, Any]) -> str:
    """ç”ŸæˆçŸ©é˜µä¹˜æ³•çš„MLIR"""
    params = case['params']
    M, K, N = params['M'], params['K'], params['N']
    dtype = params['dtype']
    
    return f"""module {{
  func.func @main(
    %A: tensor<{M}x{K}x{dtype}>,
    %B: tensor<{K}x{N}x{dtype}>
  ) -> tensor<{M}x{N}x{dtype}> {{
    %init = tensor.empty() : tensor<{M}x{N}x{dtype}>
    
    %C = linalg.matmul ins(%A, %B : tensor<{M}x{K}x{dtype}>, tensor<{K}x{N}x{dtype}>)
                      outs(%init : tensor<{M}x{N}x{dtype}>) -> tensor<{M}x{N}x{dtype}>
    
    return %C : tensor<{M}x{N}x{dtype}>
  }}
}}"""

def generate_conv_mlir(case: Dict[str, Any]) -> str:
    """ç”Ÿæˆå·ç§¯çš„MLIR"""
    params = case['params']
    N, H, W, C = params['N'], params['H'], params['W'], params['C']
    dtype = params['dtype']
    
    # å¦‚æœæ²¡æœ‰KH, KW, Få‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
    KH = params.get('KH', 3)
    KW = params.get('KW', 3)
    F = params.get('F', C)
    OH = params.get('OH', H - KH + 1)
    OW = params.get('OW', W - KW + 1)
    
    return f"""module {{
  func.func @main(
    %input: tensor<{N}x{H}x{W}x{C}x{dtype}>,
    %kernel: tensor<{KH}x{KW}x{C}x{F}x{dtype}>
  ) -> tensor<{N}x{OH}x{OW}x{F}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{OH}x{OW}x{F}x{dtype}>
    
    %output = linalg.conv_2d_nhwc_hwcf
      ins(%input, %kernel : tensor<{N}x{H}x{W}x{C}x{dtype}>, tensor<{KH}x{KW}x{C}x{F}x{dtype}>)
      outs(%init : tensor<{N}x{OH}x{OW}x{F}x{dtype}>) -> tensor<{N}x{OH}x{OW}x{F}x{dtype}>
    
    return %output : tensor<{N}x{OH}x{OW}x{F}x{dtype}>
  }}
}}"""

def generate_pooling_mlir(case: Dict[str, Any]) -> str:
    """ç”Ÿæˆæ± åŒ–çš„MLIR"""
    params = case['params']
    N, H, W, C = params['N'], params['H'], params['W'], params['C']
    dtype = params['dtype']
    
    # å¦‚æœæ²¡æœ‰OH, OWå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼
    OH = params.get('OH', H // 2)
    OW = params.get('OW', W // 2)
    
    return f"""module {{
  func.func @main(
    %input: tensor<{N}x{H}x{W}x{C}x{dtype}>
  ) -> tensor<{N}x{OH}x{OW}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{OH}x{OW}x{C}x{dtype}>
    
    %output = linalg.pooling_nhwc_max
      ins(%input : tensor<{N}x{H}x{W}x{C}x{dtype}>)
      outs(%init : tensor<{N}x{OH}x{OW}x{C}x{dtype}>)
      {{dilations = dense<1> : vector<2xi64>,
       strides = dense<2> : vector<2xi64>,
       windows = dense<2> : vector<2xi64>}}
      (%in: {dtype}, %out: {dtype}) {{
        %result = arith.maximumf %in, %out : {dtype}
        linalg.yield %result : {dtype}
      }} -> tensor<{N}x{OH}x{OW}x{C}x{dtype}>
    
    return %output : tensor<{N}x{OH}x{OW}x{C}x{dtype}>
  }}
}}"""

def generate_reduce_mlir(case: Dict[str, Any]) -> str:
    """ç”Ÿæˆå½’çº¦çš„MLIR"""
    params = case['params']
    N, H, W, C = params['N'], params['H'], params['W'], params['C']
    dtype = params['dtype']
    
    return f"""module {{
  func.func @main(
    %input: tensor<{N}x{H}x{W}x{C}x{dtype}>
  ) -> tensor<{N}x{C}x{dtype}> {{
    %init = tensor.empty() : tensor<{N}x{C}x{dtype}>
    
    %output = linalg.reduce
      ins(%input : tensor<{N}x{H}x{W}x{C}x{dtype}>)
      outs(%init : tensor<{N}x{C}x{dtype}>)
      dimensions = [1, 2]
      (%in: {dtype}, %out: {dtype}) {{
        %result = arith.addf %in, %out : {dtype}
        linalg.yield %result : {dtype}
      }} -> tensor<{N}x{C}x{dtype}>
    
    return %output : tensor<{N}x{C}x{dtype}>
  }}
}}"""

def generate_mlir(case: Dict[str, Any]) -> str:
    """æ ¹æ®æ“ä½œç±»å‹ç”ŸæˆMLIR"""
    op_id = case['op_id']
    
    # å…ƒç´ çº§æ“ä½œ
    elementwise_ops = [
        'relu', 'leaky_relu', 'elu', 'gelu', 'swish', 'mish',
        'exp', 'log', 'log2', 'log10', 'sqrt', 'rsqrt', 'cbrt',
        'sin', 'cos', 'tan', 'asin', 'acos', 'atan', 'atan2',
        'sinh', 'cosh', 'asinh', 'acosh', 'atanh',
        'sigmoid', 'softplus', 'softsign', 'hard_sigmoid', 'hard_tanh'
    ]
    
    # äºŒå…ƒæ“ä½œ
    binary_ops = ['add', 'sub', 'mul', 'div', 'mod', 'pow', 'atan2']
    
    # æ¯”è¾ƒæ“ä½œ
    comparison_ops = ['equal', 'not_equal', 'greater', 'greater_equal', 'less', 'less_equal']
    
    # é€»è¾‘æ“ä½œ
    logical_ops = ['logical_and', 'logical_or', 'logical_not', 'logical_xor']
    
    if op_id in elementwise_ops or op_id in binary_ops or op_id in comparison_ops or op_id in logical_ops:
        return generate_simple_elementwise_mlir(case)
    elif op_id == 'matmul':
        return generate_matmul_mlir(case)
    elif op_id == 'conv2d_nhwc_hwcf':
        return generate_conv_mlir(case)
    elif op_id in ['avgpool2d', 'maxpool2d']:
        return generate_pooling_mlir(case)
    elif op_id == 'reduce_sum':
        return generate_reduce_mlir(case)
    elif op_id == 'clamp':
        return generate_simple_elementwise_mlir(case)
    else:
        # é»˜è®¤ä½¿ç”¨å…ƒç´ çº§æ“ä½œ
        return generate_simple_elementwise_mlir(case)

def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®è·¯å¾„
    cases_file = Path("out/cases_single.json")
    config_file = Path("config/ops.yaml")
    template_dir = Path("templates")
    output_dir = Path("out/single")
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not cases_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°å®ä¾‹æ–‡ä»¶: {cases_file}")
        print("è¯·å…ˆè¿è¡Œ scripts/enumerate_ops.py")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½æ•°æ®
    print("ğŸ“‹ åŠ è½½æ“ä½œå®ä¾‹...")
    cases = load_cases(cases_file)
    
    print("ğŸ“‹ åŠ è½½æ“ä½œé…ç½®...")
    ops_config = load_ops_config(config_file)
    
    # ç”ŸæˆMLIRæ–‡ä»¶
    print("ğŸ”§ ç”ŸæˆMLIRæ–‡ä»¶...")
    success_count = 0
    error_count = 0
    
    for case in cases:
        try:
            # åˆ›å»ºæ“ä½œç›®å½•
            op_dir = output_dir / case['op_id']
            op_dir.mkdir(exist_ok=True)
            
            # ç”ŸæˆMLIRå†…å®¹
            mlir_content = generate_mlir(case)
            
            # ä¿å­˜æ–‡ä»¶
            output_file = op_dir / f"{case['case_id']}.mlir"
            with open(output_file, 'w') as f:
                f.write(mlir_content)
            
            success_count += 1
            print(f"âœ… æˆåŠŸç”Ÿæˆ: {case['case_id']}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¤±è´¥ {case['case_id']}: {e}")
            error_count += 1
    
    print(f"\nâœ… å®Œæˆï¼")
    print(f"  æˆåŠŸ: {success_count}")
    print(f"  å¤±è´¥: {error_count}")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")

if __name__ == "__main__":
    main()
